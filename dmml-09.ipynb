{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DMML-09\n",
        "\n",
        "Support Vector Machines.\n",
        "\n",
        "David Apagyi  \n",
        "2025-11-20\n",
        "\n",
        "**Web page:** <a href=\"https://apagyidavid.web.elte.hu/2025-2026-1/dmml\"\n",
        "target=\"_blank\">apagyidavid.web.elte.hu/2025-2026-1/dmml</a>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/dapagyi/dmml-web/blob/notebooks/dmml-09.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Support Vector Machines\n",
        "\n",
        "## Spam Classification\n",
        "\n",
        "Spam classification is a classic application of SVMs[1], as it is a\n",
        "great example that highlights the strengths of the kernel trick. In this\n",
        "example, in the feature vectors each element represents the presence or\n",
        "absence of a specific word in the email, thus they are high-dimensional\n",
        "and sparse.\n",
        "\n",
        "Also, we would afted need to map the data to a higher-dimensional space\n",
        "to make it linearly separable (or nearly so), but this would be usually\n",
        "– especially in this case – computationally expensive. Instead, we would\n",
        "use the kernel trick to compute the inner products in the\n",
        "higher-dimensional space without explicitly mapping the data points. (We\n",
        "don’t even need to know what the explicit mapping is. Also, the kernel\n",
        "might correspond to a mapping to an infinite-dimensional space.)\n",
        "\n",
        "We won’t cover this example in detail here, but *it is highly\n",
        "recommended* to at least skim through <a\n",
        "href=\"https://vkosuri.github.io/CourseraMachineLearning/home/week-7/exercises/machine-learning-ex6/ex6.pdf\"\n",
        "target=\"_blank\">this task description (Exercise 2)</a>[2] and\n",
        "<a href=\"https://gtraskas.github.io/post/ex6_spam/\" target=\"_blank\">this\n",
        "solution</a>[3] using a linear kernel.\n",
        "\n",
        "In general, SVMs can be very effective (aften can achieve similar\n",
        "performance as tree-based models), but usually they require extensive\n",
        "(or at least more careful) hyperparameter tuning.\n",
        "\n",
        "## Visualizing Different Kernels\n",
        "\n",
        "[1] See\n",
        "<a href=\"https://ieeexplore.ieee.org/document/788645\" target=\"_blank\">H.\n",
        "Drucker, Donghui Wu and V. N. Vapnik, “Support vector machines for spam\n",
        "categorization”</a> for more details.\n",
        "\n",
        "[2] The original exercise is from a previous iteration of Andrew Ng’s\n",
        "Machine Learning course on Coursera.\n",
        "\n",
        "[3] <a href=\"https://gtraskas.github.io/post/ex6/\" target=\"_blank\">This is a\n",
        "solution</a> from the same author for the first exercise. (The task is\n",
        "about the decision boundaries of an SVM using an RBF kernel. We will do\n",
        "something similar in the next section.)\n",
        "<a href=\"https://github.com/kaleko/CourseraML/tree/master/ex6\"\n",
        "target=\"_blank\">Here is another solution for the spam classification\n",
        "task.</a>"
      ],
      "id": "4bf67271-5cbd-440f-8a46-cd6055428822"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from sklearn.datasets import make_circles, make_classification, make_moons\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "def plot_decision_boundary(ax, clf, X, y, title, kernel_name):\n",
        "    if clf is None:\n",
        "        # Show TODO placeholder\n",
        "        ax.text(\n",
        "            0.5,\n",
        "            0.5,\n",
        "            \"TODO\",\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            fontsize=14,\n",
        "            bbox=dict(boxstyle=\"round,pad=1\", facecolor=\"wheat\", alpha=0.5),\n",
        "            transform=ax.transAxes,\n",
        "        )\n",
        "        ax.set_title(f\"{title} | {kernel_name}\", fontsize=10)\n",
        "        ax.set_xlabel(\"Feature 1\", fontsize=9)\n",
        "        ax.set_ylabel(\"Feature 2\", fontsize=9)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "        return\n",
        "\n",
        "    y_pred = clf.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "    DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        ax=ax,\n",
        "        response_method=\"predict\",\n",
        "        plot_method=\"pcolormesh\",\n",
        "        cmap=plt.cm.RdYlBu,\n",
        "        alpha=0.3,\n",
        "    )\n",
        "    ax.set_xlabel(\"Feature 1\", fontsize=9)\n",
        "    ax.set_ylabel(\"Feature 2\", fontsize=9)\n",
        "\n",
        "    n_classes = len(np.unique(y))\n",
        "    if n_classes == 2:\n",
        "        contour_display = DecisionBoundaryDisplay.from_estimator(\n",
        "            clf,\n",
        "            X,\n",
        "            ax=ax,\n",
        "            response_method=\"decision_function\",\n",
        "            plot_method=\"contour\",\n",
        "            levels=[-2, -1, 0, 1, 2],\n",
        "            colors=[\"k\", \"k\", \"k\", \"k\", \"k\"],\n",
        "            linestyles=[\":\", \"--\", \"-\", \"--\", \":\"],\n",
        "            alpha=0.7,\n",
        "        )\n",
        "        ax.clabel(contour_display.surface_, inline=True, fontsize=8, fmt=\"%.1f\")\n",
        "\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors=\"k\", s=50, alpha=0.7)\n",
        "    ax.set_title(f\"{title} | {kernel_name} \\n Accuracy: {accuracy:.3f}\", fontsize=10)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def svm_demo(datasets, kernels):\n",
        "    fig, axes = plt.subplots(len(kernels), len(datasets), figsize=(5 * len(datasets), 5 * len(kernels)))\n",
        "    fig.suptitle(\n",
        "        \"SVM Kernel Comparison: Decision Boundaries Across Different Datasets\", fontsize=16, y=0.995, weight=\"semibold\"\n",
        "    )\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for row, (kernel_name, kernel_params) in enumerate(kernels):\n",
        "        scores = {}\n",
        "        for col, (dataset_name, dataset) in enumerate(datasets):\n",
        "            ax = axes[row, col]\n",
        "\n",
        "            if kernel_params is None or dataset is None:\n",
        "                # Show TODO placeholder\n",
        "                plot_decision_boundary(ax, None, None, None, dataset_name, kernel_name)\n",
        "            else:\n",
        "                X, y = dataset\n",
        "                clf = SVC(**kernel_params)\n",
        "                clf.fit(X, y)\n",
        "\n",
        "                score = plot_decision_boundary(ax, clf, X, y, dataset_name, kernel_name)\n",
        "                scores[dataset_name] = score\n",
        "\n",
        "        if scores:\n",
        "            results[kernel_name] = scores\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    data = []\n",
        "    for kernel, scores in results.items():\n",
        "        data.append({\"Kernel\": kernel, **scores})\n",
        "    df = pl.DataFrame(data).with_columns(pl.mean_horizontal(pl.all().exclude(\"Kernel\")).alias(\"Average Accuracy\"))\n",
        "    display(df)"
      ],
      "id": "6c3660f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise:** Extend the dataset generation and kernel configurations\n",
        "below and play around with different parameters. What are the meaning of\n",
        "`gamma` and `C` in the SVC model? How do they affect the decision\n",
        "boundaries? Try out different values (you might need to select these\n",
        "from quite wide ranges).\n",
        "\n",
        "Some useful links:\n",
        "\n",
        "-   <a\n",
        "    href=\"https://scikit-learn.org/stable/api/sklearn.datasets.html#sample-generators\"\n",
        "    target=\"_blank\">Sample generators</a>\n",
        "-   <a\n",
        "    href=\"https://scikit-learn.org/stable/modules/svm.html#support-vector-machines\"\n",
        "    target=\"_blank\">User Guide: Support Vector Machines</a>\n",
        "-   <a\n",
        "    href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\"\n",
        "    target=\"_blank\">SVC documentation</a>\n",
        "\n",
        "**Question:** How would you approach multiclass classification with\n",
        "SVMs? (Check <a\n",
        "href=\"https://scikit-learn.org/stable/modules/svm.html#multi-class-classification\"\n",
        "target=\"_blank\">the second link above</a> or <a\n",
        "href=\"https://en.wikipedia.org/wiki/Support_vector_machine#:~:text=%5Bedit%5D-,Multiclass%20SVM,-%5Bedit%5D\"\n",
        "target=\"_blank\">Wikipedia.</a>)"
      ],
      "id": "003fb423-728d-440d-9023-cd0755529b36"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def generate_datasets(n_samples=200, seed=42):\n",
        "    # Linear separable data\n",
        "    X_linear, y_linear = make_classification(\n",
        "        n_samples=n_samples,\n",
        "        n_features=2,\n",
        "        n_redundant=0,\n",
        "        n_informative=2,\n",
        "        n_clusters_per_class=1,\n",
        "        flip_y=0.01,\n",
        "        class_sep=1.5,\n",
        "        random_state=seed + 2,\n",
        "    )\n",
        "\n",
        "    # Circular/non-linear data\n",
        "    X_circles, y_circles = make_circles(n_samples=n_samples, noise=0.1, factor=0.5, random_state=seed + 4)\n",
        "\n",
        "    # TODO: Moon-shaped data\n",
        "\n",
        "    # TODO: Multiclass data\n",
        "\n",
        "    # (You may choose other datasets as well.)\n",
        "\n",
        "    return [\n",
        "        (\"Linear Separable\", (X_linear, y_linear)),\n",
        "        (\"Concentric Circles\", (X_circles, y_circles)),\n",
        "        (\"Interleaving Moons\", None),\n",
        "        (\"Multiclass Classification\", None),\n",
        "    ]\n",
        "\n",
        "\n",
        "datasets = generate_datasets()\n",
        "common_params = dict(gamma=\"auto\", C=1.0)\n",
        "kernels = [\n",
        "    (\"Linear Kernel\", dict(kernel=\"linear\", **common_params)),\n",
        "    (\"Sigmoid Kernel\", dict(kernel=\"sigmoid\", **common_params)),\n",
        "    (\"Polynomial Kernel\", None),  # TODO\n",
        "    (\"RBF (Radial Basis Function) Kernel\", None),  # TODO\n",
        "    # (You may choose other kernels as well.)\n",
        "]\n",
        "svm_demo(datasets, kernels)"
      ],
      "id": "42ad509e"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/runner/work/dmml-web/dmml-web/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  }
}